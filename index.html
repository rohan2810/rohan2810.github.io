<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Rohan Surana | AI Researcher</title>
    <link rel="stylesheet" href="css/main.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css">
</head>
<body>
    <!-- Sidebar -->
    <aside class="sidebar">
        <img src="images/rohan-profile.jpg" alt="Rohan Surana" class="profile-img">
        
        <nav class="nav-menu">
            <a href="#about" class="nav-item">About Me</a>
            <a href="#research" class="nav-item">Research Topics</a>
            <a href="#experience" class="nav-item">Experience</a>
            <a href="#teaching" class="nav-item">Teaching</a>
            <a href="#education" class="nav-item">Education</a>
            <a href="#projects" class="nav-item">Projects</a>
            <a href="#skills" class="nav-item">Technical Skills</a>
            <a href="assets/resume.pdf" class="nav-item" target="_blank">Resume / CV</a>
        </nav>

        <div class="social-links">
            <a href="https://github.com/rohan2810" class="social-link" target="_blank" title="GitHub"><i class="fab fa-github"></i></a>
            <a href="https://linkedin.com/in/rohansurana28/" class="social-link" target="_blank" title="LinkedIn"><i class="fab fa-linkedin"></i></a>
            <a href="mailto:rohansurana2810@gmail.com" class="social-link" title="Email"><i class="fas fa-envelope"></i></a>
        </div>
        <div style="margin-top: 15px; color: rgba(255,255,255,0.7); font-size: 0.8rem; text-align: center;">
            rohansurana2810@gmail.com
        </div>
    </aside>

    <!-- Main Content -->
    <main class="main-content">
        <!-- About Section -->
        <section id="about" class="bio-section">
            <h1>Rohan Surana</h1>
            <p class="subtitle">Masters Student in Data Science @ UCSD | AI Research Intern @ Dell</p>
            
            <p>
                I am a Master's student in Data Science at the <strong>University of California, San Diego (UCSD)</strong>, 
                advised by <a href="https://cseweb.ucsd.edu/~jmcauley/" target="_blank">Prof. Julian McAuley</a>, and an AI Research Intern at 
                <strong>Dell Technologies</strong>. I previously earned my B.S. in Software Engineering, summa cum laude, from 
                <strong>San Jose State University</strong>.
            </p>
            <p>
                My research sits at the intersection of <strong>preference optimization</strong>, <strong>information retrieval</strong>, 
                and <strong>multimodal learning</strong>. I develop alignment and post-training methods that help LLMs learn human preferences 
                from structured but sparse signals, including pairwise choices, ranked slates, and in-context listwise feedback. Recent work 
                includes multi-negative DPO with principled negative selection, in-context ranking and exploration objectives for retrieval and 
                recommendation, and multimodal extensions that reduce hallucinations through diverse visual negatives and modality-steering. 
                I also build practical IR and conversational recommender systems, such as active dialogue synthesis for zero or low resource 
                domains and benchmarks for audio-centric conversational recommendation. Across these projects, my goal is to make models more 
                <strong>sample-efficient, reliable, and interpretable</strong>, while improving real-world decision quality.
            </p>
        </section>

        <!-- What's New Section -->
        <section id="news">
            <h2>What's New</h2>
            <ul class="updates-list">
                 <li class="update-item">
                    <span class="update-date">[Dec 2025]</span>
                     Attending <strong>NeurIPS 2025</strong> in San Diego, CA.
                </li>
                 <li class="update-item">
                    <span class="update-date">[Sep 2025]</span>
                     Completed internship at Dell Technologies!
                </li>
                <li class="update-item">
                    <span class="update-date">[Jun 2025]</span>
                     Joined <strong>Dell Technologies</strong> as an AI Research Intern in Hopkinton, MA.
                </li>
                 <li class="update-item">
                    <span class="update-date">[May 2025]</span>
                     Our paper "In-context Ranking Preference Optimization" was accepted to <strong>COLM 2025</strong>.
                </li>
                <li class="update-item">
                    <span class="update-date">[May 2025]</span>
                     Our paper "Traceable and Explainable Multimodal LLMs" was accepted to <strong>COLM 2025</strong>.
                </li>
                <li class="update-item">
                    <span class="update-date">[May 2025]</span>
                     Our paper "Image Difference Captioning via Adversarial Preference Optimization" was accepted to <strong>EMNLP 2025</strong>.
                </li>
            </ul>
        </section>

        <!-- Research Topics / Publications -->
        <section id="research">
            <h2>Research Topics</h2>
            
            <!-- Tabs -->
            <div class="research-tabs">
                <button class="tab-btn active" onclick="openTab(event, 'llm')">LLM Alignment & Post-training</button>
                <button class="tab-btn" onclick="openTab(event, 'ir')">IR & Recommendation</button>
                <button class="tab-btn" onclick="openTab(event, 'multimodal')">Multimodal Learning</button>
            </div>

            <!-- Tab Content: LLM -->
            <div id="llm" class="tab-content active">
                <div class="paper-item">
                    <div class="paper-row">
                        <div class="paper-thumb">
                            <img src="images/mass-dpo.png" onerror="this.style.display='none'" alt="MASS-DPO" class="paper-img-thumb">
                        </div>
                        <div class="paper-content">
                            <div class="paper-title">MASS-DPO: Multi-Negative Active Sample Selection for Direct Policy Optimization</div>
                            <div class="paper-authors"><strong>Rohan Surana*</strong>, J. Wu*, X. Li, Y. Shen, C. Wang, T. Yu, P. Ammanabrolu, J. Shang, J. McAuley</div>
                            <div class="paper-venue">Submitted</div>
                            <p class="paper-desc">
                                We cast multi-negative DPO under the Plackett-Luce model as a D-optimal design problem and develop a greedy, theoretically grounded selection strategy for informative negatives. This improves alignment efficiency and performance.
                            </p>
                        </div>
                    </div>
                </div>

                <div class="paper-item">
                     <div class="paper-row">
                        <div class="paper-thumb">
                            <img src="images/irpo.png" onerror="this.style.display='none'" alt="IRPO" class="paper-img-thumb">
                        </div>
                         <div class="paper-content">
                            <div class="paper-title">In-context Ranking Preference Optimization (IRPO)</div>
                            <div class="paper-authors">J. Wu*, <strong>Rohan Surana*</strong>, Z. Xie, Y. Shen, Y. Xia, T. Yu, R. Rossi, P. Ammanabrolu, J. McAuley</div>
                            <div class="paper-venue">COLM 2025</div>
                            <p class="paper-desc">
                                We extend Direct Preference Optimization to ranking, allowing LLMs to learn from sparse, in-context listwise feedback and directly optimize differentiable surrogates of ranking metrics. This connects preference optimization with practical IR settings like conversational recommendation and generative retrieval.
                            </p>
                            <div style="margin-top: 5px;">
                                <a href="https://arxiv.org/pdf/2504.15477" target="_blank" class="paper-link">[PDF]</a>
                            </div>
                        </div>
                    </div>
                </div>

                <div class="paper-item">
                    <div class="paper-row">
                        <div class="paper-thumb">
                            <img src="images/misp-dpo.png" onerror="this.style.display='none'" alt="MISP-DPO" class="paper-img-thumb">
                        </div>
                        <div class="paper-content">
                            <div class="paper-title">Importance Sampling for Multi-Negative Multimodal Direct Preference Optimization (MISP-DPO)</div>
                            <div class="paper-authors">X. Li, C. Wang, J. Wu, <strong>Rohan Surana</strong>, T. Yu, J. McAuley, J. Shang</div>
                            <div class="paper-venue">Submitted</div>
                            <p class="paper-desc">
                                We extend multi-negative DPO to the multimodal setting, using a CLIP+SAE-based sampler and importance sampling under a Plackett–Luce objective to select semantically diverse visual negatives. This substantially improves multimodal alignment and reduces hallucinations compared to single-negative multimodal DPO baselines.
                            </p>
                        </div>
                    </div>
                </div>

                <div class="paper-item">
                    <div class="paper-row">
                        <div class="paper-thumb">
                            <img src="images/ws-grpo.png" onerror="this.style.display='none'" alt="WS-GRPO" class="paper-img-thumb">
                        </div>
                        <div class="paper-content">
                            <div class="paper-title">WS-GRPO: Weakly-Supervised Group-Relative Policy Optimization</div>
                            <div class="paper-authors">G. Mundada*, <strong>Rohan Surana*</strong>, J. Y. Zhang, X. Li, T. Yu, L. Yao, J. Shang, J. McAuley, J. Wu</div>
                            <div class="paper-venue">Submitted</div>
                            <p class="paper-desc">
                                We address GRPO's dependence on dense step-wise rewards by learning to extract dense preference signals from sparse outcome supervision. WS-GRPO trains a preference model on trajectory-level outcomes, then leverages it to provide step-wise weakly-supervised rewards combined with terminal rewards during group-relative policy optimization. This enables effective reasoning model training without expensive step-by-step annotations.
                            </p>
                        </div>
                    </div>
                </div>

                <div class="paper-item">
                    <div class="paper-row">
                        <div class="paper-thumb">
                            <img src="images/rlvr-survey.png" onerror="this.style.display='none'" alt="RLVR Survey" class="paper-img-thumb">
                        </div>
                        <div class="paper-content">
                            <div class="paper-title">From Verifiable Rewards to Policy Learning: A Survey of Reinforcement Learning from Verifiable Rewards</div>
                            <div class="paper-authors">G. Mundada*, <strong>Rohan Surana*</strong>, S. Yu, J. Y. Zhang, Z. Huang, Y. Xiong, X. Li, Y. Xia, R. Jain, C. Huang, N. L. Kuang, T. Yu, R. A. Rossi, D. Zhou, L. Yao, J. Shang, J. McAuley, J. Wu</div>
                            <div class="paper-venue">Survey Paper</div>
                            <p class="paper-desc">
                                We provide the first comprehensive survey of Reinforcement Learning from Verifiable Rewards (RLVR), systematizing methods that train language models using verifier feedback. We introduce taxonomies organizing approaches by verification type, reward computation, and policy learning, establishing unified terminology for mathematical reasoning, code generation, and instruction following.
                            </p>
                        </div>
                    </div>
                </div>
            </div>

            <!-- Tab Content: IR -->
            <div id="ir" class="tab-content">
                <div class="paper-item">
                    <div class="paper-row">
                        <div class="paper-thumb">
                             <img src="images/crs-syn.png" onerror="this.style.display='none'" alt="CRS Synthesis" class="paper-img-thumb">
                        </div>
                        <div class="paper-content">
                            <div class="paper-title">From Reviews to Dialogues: Active Synthesis for Zero-Shot LLM-based Conversational Recommender System</div>
                            <div class="paper-authors"><strong>Rohan Surana*</strong>, J. Wu*, Z. Xie*, Y. Xia, H. Steck, D. Liang, N. Kallus, J. McAuley</div>
                            <div class="paper-venue">Preprint</div>
                            <p class="paper-desc">
                                Joint work with Netflix where we design an active data augmentation framework that turns static domain data (reviews, metadata, collaborative signals) into synthetic conversations using black-box LLMs, enabling smaller in-house CRS models to operate in true zero-/low-resource settings.
                            </p>
                            <div style="margin-top: 5px;">
                                <a href="https://arxiv.org/pdf/2504.15476" target="_blank" class="paper-link">[PDF]</a>
                            </div>
                        </div>
                    </div>
                </div>

                <div class="paper-item">
                    <div class="paper-row">
                        <div class="paper-thumb">
                             <img src="images/musicrs.png" onerror="this.style.display='none'" alt="MusiCRS" class="paper-img-thumb">
                        </div>
                        <div class="paper-content">
                            <div class="paper-title">MusiCRS: Benchmarking Audio-Centric Conversational Recommendation</div>
                            <div class="paper-authors"><strong>Rohan Surana*</strong>, A. Namburi*, G. Mundada*, A. Lal*, Z. Novack, J. McAuley, J. Wu</div>
                            <div class="paper-venue">Submitted</div>
                            <p class="paper-desc">
                                We build the first benchmark that ties real conversational queries to actual music tracks, enabling evaluation across audio-only, text-only, and audio+text settings. This exposes how current CRS models over-rely on text and struggle with nuanced audio reasoning.
                            </p>
                            <div style="margin-top: 5px;">
                                <a href="https://arxiv.org/pdf/2509.19469" target="_blank" class="paper-link">[PDF]</a>
                            </div>
                        </div>
                    </div>
                </div>
            </div>

            <!-- Tab Content: Multimodal -->
            <div id="multimodal" class="tab-content">
                <div class="paper-item">
                    <div class="paper-row">
                        <div class="paper-thumb">
                             <img src="images/traceable-mllm.png" onerror="this.style.display='none'" alt="Traceable MLLM" class="paper-img-thumb">
                        </div>
                        <div class="paper-content">
                            <div class="paper-title">Traceable and Explainable Multimodal Large Language Models: An Information-Theoretic View</div>
                            <div class="paper-authors">Z. Huang, J. Wu, <strong>Rohan Surana</strong>, R. Jain, T. Yu, R. Addanki, D. Arbour, S. Kim, J. McAuley</div>
                            <div class="paper-venue">COLM 2025</div>
                            <p class="paper-desc">
                                We propose an information-theoretic framework (via a concept bottleneck and mutual-information-style measures) to make MLLMs more traceable: quantifying how much visual information is retained, transformed, or discarded as it flows through the model under different textual instructions.
                            </p>
                            <div style="margin-top: 5px;">
                                <a href="https://openreview.net/pdf?id=pQm66IPmeE" target="_blank" class="paper-link">[PDF]</a>
                            </div>
                        </div>
                    </div>
                </div>

                <div class="paper-item">
                    <div class="paper-row">
                        <div class="paper-thumb">
                             <img src="images/image-diff.png" onerror="this.style.display='none'" alt="Image Diff Captioning" class="paper-img-thumb">
                        </div>
                        <div class="paper-content">
                            <div class="paper-title">Image Difference Captioning via Adversarial Preference Optimization</div>
                            <div class="paper-authors">Z. Huang, J. Wu, <strong>Rohan Surana</strong>, T. Yu, D. Arbour, R. Sinha, J. McAuley</div>
                            <div class="paper-venue">EMNLP 2025</div>
                            <p class="paper-desc">
                                We formulate image difference captioning as a preference-optimization problem and introduce an adversarial hard-negative retriever plus DPO-style training to better capture fine-grained visual differences. This combines multimodal reasoning with preference-based training.
                            </p>
                            <div style="margin-top: 5px;">
                                <a href="https://aclanthology.org/2025.emnlp-main.1713.pdf" target="_blank" class="paper-link">[PDF]</a>
                            </div>
                        </div>
                    </div>
                </div>

                <div class="paper-item">
                    <div class="paper-row">
                        <div class="paper-thumb">
                             <img src="images/amps.png" onerror="this.style.display='none'" alt="AMPS" class="paper-img-thumb">
                        </div>
                        <div class="paper-content">
                            <div class="paper-title">AMPS: Adaptive Modality Preference Steering via Functional Entropy</div>
                            <div class="paper-authors">Z. Huang, X. Li, J. Wu, <strong>Rohan Surana</strong>, T. Yu, R. Wang, J. McAuley, J. Shang</div>
                            <div class="paper-venue">Submitted</div>
                            <p class="paper-desc">
                                We study modality preference in MLLMs (e.g., over-reliance on text vs. images) and propose an entropy-based diagnostic plus a sample-wise steering mechanism that adjusts steering intensity per input to avoid generation collapse while still shifting modality usage in a controlled way.
                            </p>
                        </div>
                    </div>
                </div>
            </div>
        </section>

        <!-- Experience Section -->
        <section id="experience">
            <h2>Experience</h2>
            <div class="timeline">
                <!-- Dell Technologies Group -->
                <div class="timeline-item company-group">
                    <div class="company-header">
                        <img src="images/dell-logo.png" alt="Dell Technologies" class="company-logo" onerror="this.style.display='none'">
                        <div class="company-info">
                            <h3>Dell Technologies</h3>
                            <p class="company-duration">Jul 2022 - Sept 2025</p>
                        </div>
                    </div>
                    
                    <div class="roles-container">
                        <!-- AI Research Intern -->
                        <div class="role-item">
                            <div class="timeline-date">June 2025 - Sept 2025</div>
                            <div class="timeline-content">
                                <h4 class="role-title">AI Research Intern | Hopkinton, MA</h4>
                                <p class="exp-summary">Built production-grade multi-agent LLM systems with 40% latency reduction, scalable RAG pipelines, and autonomous monitoring infrastructure.</p>
                            </div>
                        </div>
                        
                        <!-- Software Engineer II -->
                        <div class="role-item">
                            <div class="timeline-date">Mar 2024 - Aug 2024</div>
                            <div class="timeline-content">
                                <h4 class="role-title">Software Engineer II | Santa Clara, CA</h4>
                                <p class="exp-summary">Architected TOSCA-based orchestration framework and real-time infrastructure digital twin with graph databases, achieving 30% faster provisioning and 25% response time improvement.</p>
                            </div>
                        </div>
                        
                        <!-- Software Engineer I -->
                        <div class="role-item">
                            <div class="timeline-date">Jul 2022 - Mar 2024</div>
                            <div class="timeline-content">
                                <h4 class="role-title">Software Engineer I | Santa Clara, CA</h4>
                                <p class="exp-summary">Automated GPU-accelerated ML infrastructure with Kubernetes operators (20% faster deployment), redesigned gRPC services leading a 4-person team, and expanded observability coverage by 30%.</p>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Machine Learning Researcher -->
                <div class="timeline-item">
                    <div class="timeline-date">Aug 2021 – May 2022</div>
                    <div class="timeline-content">
                        <div class="exp-with-logo">
                            <img src="images/spartan-logo.png" alt="Spartan Superway" class="exp-logo" onerror="this.style.display='none'">
                            <div>
                                <h3>Machine Learning Researcher</h3>
                                <h4>Spartan Superway | San Jose, CA</h4>
                            </div>
                        </div>
                        <p class="exp-summary">Developed real-time vehicle detection and tracking system using YOLOv5 and BiLSTM for autonomous transportation, achieving 0.45 RMSE.</p>
                    </div>
                </div>

                <!-- Open Source Developer -->
                <div class="timeline-item">
                    <div class="timeline-date">Feb 2021 – Mar 2021</div>
                    <div class="timeline-content">
                        <div class="exp-with-logo">
                            <img src="images/apache-logo.png" alt="Apache" class="exp-logo" onerror="this.style.display='none'">
                            <div>
                                <h3>Open Source Developer</h3>
                                <h4>The Apache Software Foundation | Remote</h4>
                            </div>
                        </div>
                        <p class="exp-summary">Contributed to Apache Tika, enhancing file detection and content analysis capabilities.</p>
                    </div>
                </div>

                <!-- Software Developer Intern -->
                <div class="timeline-item">
                    <div class="timeline-date">May 2020 – Aug 2020</div>
                    <div class="timeline-content">
                        <div class="exp-with-logo">
                            <img src="images/confluxsys-logo.png" alt="Confluxsys" class="exp-logo" onerror="this.style.display='none'">
                            <div>
                                <h3>Software Developer Intern</h3>
                                <h4>Confluxsys LLC | Menlo Park, CA</h4>
                            </div>
                        </div>
                        <p class="exp-summary">Built data mining modules using Spark, Scala, and GNNs, improving pipeline throughput by 25% and reducing job runtimes by 45% for healthcare and finance clients.</p>
                    </div>
                </div>
            </div>
        </section>

        <!-- Teaching Section -->
        <section id="teaching">
            <h2>Teaching</h2>
            <div class="teaching-list">
                <div class="teaching-item">
                    <div class="teaching-header">
                        <img src="images/ucsd-logo.png" alt="UCSD" class="teaching-logo" onerror="this.style.display='none'">
                        <div class="teaching-info">
                            <div class="teaching-role">Graduate Teaching Assistant</div>
                            <div class="teaching-institution">University of California, San Diego</div>
                            <div class="teaching-period">Mar 2025 – Present</div>
                        </div>
                    </div>
                    <ul class="teaching-courses">
                        <li><strong>CSE 258:</strong> Web Mining and Recommender Systems (Sep 2025 - Present)</li>
                        <li><strong>CSE 153:</strong> Machine Learning for Music (Mar 2025 - Sep 2025)</li>
                    </ul>
                </div>

                <div class="teaching-item">
                    <div class="teaching-header">
                        <img src="images/sjsu-logo.png" alt="SJSU" class="teaching-logo" onerror="this.style.display='none'">
                        <div class="teaching-info">
                            <div class="teaching-role">Teaching Assistant & Tutor</div>
                            <div class="teaching-institution">San Jose State University</div>
                            <div class="teaching-period">Jan 2020 – May 2022</div>
                        </div>
                    </div>
                    <ul class="teaching-courses">
                        <li><strong>CS Peer Tutor:</strong> SJSU Peer Connections (Jan 2022 - May 2022)</li>
                        <li><strong>CS46B:</strong> Introduction to Data Structures (Aug 2021 - May 2022)</li>
                        <li><strong>CS149:</strong> Operating Systems (Aug 2021 - Jan 2022)</li>
                        <li><strong>Math Workshop Facilitator:</strong> Calculus II (Jan 2020 - Aug 2021)</li>
                    </ul>
                </div>
            </div>
        </section>

        <!-- Education Section -->
        <section id="education">
            <h2>Education</h2>
            
            <div class="education-grid">
                <!-- UCSD -->
                <div class="edu-card">
                    <div class="edu-logo-placeholder ucsd-logo">
                         <img src="images/ucsd-logo.png" alt="UCSD Logo" onerror="this.style.display='none'; this.parentNode.innerText='UCSD'">
                    </div>
                    <div class="edu-school">University of California, San Diego</div>
                    <div class="edu-period">Sept. 2024 - Mar. 2026 (Expected)</div>
                    <div class="edu-details">
                        <p><strong>Masters of Science in Data Science</strong></p>
                        <p>GPA: 3.88/4.00</p>
                        <p>Advisor: <a href="https://cseweb.ucsd.edu/~jmcauley/" target="_blank">Prof. Julian McAuley</a></p>
                    </div>
                </div>

                <!-- SJSU -->
                <div class="edu-card">
                    <div class="edu-logo-placeholder sjsu-logo">
                         <img src="images/sjsu-logo.png" alt="SJSU Logo" onerror="this.style.display='none'; this.parentNode.innerText='SJSU'">
                    </div>
                    <div class="edu-school">San Jose State University</div>
                    <div class="edu-period">Aug. 2018 - May 2022</div>
                    <div class="edu-details">
                        <p><strong>Bachelor of Science in Software Engineering</strong></p>
                        <p>GPA: 3.87/4.00 (Summa Cum Laude)</p>
                    </div>
                </div>
            </div>
        </section>

        <!-- Projects Section -->
        <section id="projects">
            <h2>Projects</h2>
            
            <div class="project-grid">
                <!-- Project 1 -->
                <div class="project-card">
                     <div class="project-content">
                        <div class="exp-header">
                            <span class="exp-role">Privacy-Preserving LLM Training with Synthetic Data</span>
                            <span class="exp-date">Sept 2024 – Dec 2024</span>
                        </div>
                        <div class="tech-stack"><em>CrewAI, Unsloth, PyTorch, Llama-2</em></div>
                        <p class="exp-summary">Designed multi-agent framework for PII-safe data generation and fine-tuned 2 open-source LLMs achieving 99% PII removal with 270-question evaluation benchmark.</p>
                     </div>
                </div>

                <!-- Project 2 -->
                <div class="project-card">
                     <div class="project-content">
                        <div class="exp-header">
                            <span class="exp-role">Autonomous Transportation Computer Vision System</span>
                            <span class="exp-date">Jan 2022 – May 2022</span>
                        </div>
                         <div class="tech-stack"><em>YOLOv5, TensorFlow, OpenCV</em></div>
                        <p class="exp-summary">Built real-time vehicle detection and tracking system with YOLOv5 and BiLSTM achieving 0.45 RMSE, optimized for Raspberry Pi deployment.</p>
                     </div>
                </div>
            </div>
        </section>

        <!-- Skills Section -->
        <section id="skills">
            <h2>Technical Skills</h2>
            <ul class="skills-list">
                <li><strong>Languages:</strong> Python, Golang, Java, Scala, SQL</li>
                <li><strong>ML/DL:</strong> PyTorch, TensorFlow, scikit-learn, Transformers, OpenCV, NumPy, Pandas</li>
                <li><strong>LLM/NLP:</strong> LangGraph, LangChain, vLLM, Unsloth, CrewAI, Hugging Face</li>
                <li><strong>Infrastructure:</strong> Kubernetes, Docker, FastAPI, Spark, gRPC, Git, MLflow, Ray, AWS, GCP</li>
                <li><strong>Databases:</strong> ChromaDB, MySQL, PostgreSQL, Dgraph, Neo4j, MongoDB</li>
            </ul>
        </section>

        <footer style="margin-top: 60px; color: #777; font-size: 0.9rem; border-top: 1px solid #eee; padding-top: 20px;">
            <p>© 2024-2025 Rohan Surana. Inspired by <a href="https://cs.stanford.edu/~shirwu/" target="_blank">Shirley Wu's website</a>.</p>
        </footer>
    </main>

    <script>
        function openTab(evt, tabName) {
            var i, tabcontent, tablinks;
            tabcontent = document.getElementsByClassName("tab-content");
            for (i = 0; i < tabcontent.length; i++) {
                tabcontent[i].style.display = "none";
                tabcontent[i].classList.remove("active");
            }
            tablinks = document.getElementsByClassName("tab-btn");
            for (i = 0; i < tablinks.length; i++) {
                tablinks[i].className = tablinks[i].className.replace(" active", "");
            }
            document.getElementById(tabName).style.display = "block";
            document.getElementById(tabName).classList.add("active");
            evt.currentTarget.className += " active";
        }
    </script>
</body>
</html>
